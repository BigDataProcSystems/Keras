{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Рекуррентная нейронная сеть и </b> <span style=\"font-weight:bold; color:green\">Keras</span></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_hse@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение стилей оформления</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import rnn_lang_modeling_reader as reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Загрузка исходных данных</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Вариант 1.</b> Из командной строки</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget wget -P data/rnn-lang-modeling/ http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvf data/rnn-lang-modeling/simple-examples.tgz -C data/rnn-lang-modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Вариант 2.</b> Средствами Python</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\"\n",
    "\n",
    "filename = \"data/rnn-lang-modeling/rnn-simple.tgz\"\n",
    "\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "# Загрузка архива\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    with open(filename, 'wb') as output:\n",
    "        shutil.copyfileobj(response, output)\n",
    "\n",
    "# Распаковка\n",
    "with tarfile.open(filename) as tar:\n",
    "    tar.extractall(path=\"data/rnn-lang-modeling/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Директория с исходными данными и для записи логов и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/rnn-lang-modeling/simple-examples/data\"\n",
    "save_path = \"log/rnn-lang-modeling/log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных и преобразование в вектор индексов слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocabulary = reader.ptb_raw_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество слов (токенов) в обучающем подмножестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс первого слова в тестовом подмножестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь преобразования слов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратное пребразование индекса первого слова тестового подмножества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in vocabulary:\n",
    "    if vocabulary[key] == test_data[0]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Этапы построения сети</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 24 # количество развертки LSTM\n",
    "hidden_size = 200 # количество LSTM единиц\n",
    "vocab_size = 10000 # размер словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры инициализации весов и параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0 # коэффициент скорости обучения\n",
    "max_grad_norm = 5 # предельно допустимая норма градиента\n",
    "max_max_epoch = 4 # количество эпох\n",
    "batch_size = 20 # размер batch\n",
    "num_steps_test = 1 # количество развертки LSTM при тестировании\n",
    "batch_size_test = 1 # размер batch при тестировании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = ((len(train_data) // batch_size) - 1) // num_steps # размер epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, hidden_size, input_length=num_steps, trainable=False))\n",
    "                        #batch_input_shape=(batch_size, num_steps), trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hidden_size, return_sequences=True))#, bias_initializer='zeros', stateful=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hidden_size, return_sequences=False))#, bias_initializer='zeros', stateful=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=learning_rate, clipnorm=max_grad_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LSTM архитектура сети</b>\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/lstm_architecture.png\" width=\"541px\">\n",
    "\n",
    "Размерность входных текстовых данных упорядочена следующим образом: (размер batch, количество развертки LSTM, количество LSTM единиц). \n",
    "\n",
    "Так для каждого batch и каждого слова в развертке LSTM существует вектор слоя внедрения длиной 200 для представления входного слова. Входные данные подаются в два «сложенных» слоя слотов LSTM. Вывод из этих развернутых слотов остается неизменным (размер batch, количество развертки LSTM, количество LSTM единиц).\n",
    "\n",
    "Затем выходные данные передаются в полностью связанный слой Dense, на котором применяется функция активации softmax, возвращая массив вероятностных оценок. Оценки сравниваются с данными обучения y для каждой соты, затем выполняется обратное распространение ошибки и градиента. \n",
    "\n",
    "Так на каждом временном шаге модель пытается предсказать следующее следующее слово в последовательности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Запуск обучения</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, input_data, batch_size, num_steps, verbose=False):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    losses = 0.0\n",
    "    iters = 0\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(input_data, batch_size, num_steps)):\n",
    "        y = to_categorical(y, num_classes=vocab_size)\n",
    "        loss = model.train_on_batch(x, y)\n",
    "        losses += loss\n",
    "        iters += num_steps\n",
    "        \n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(\"%.3f perplexity: %.3f speed: %.0f wps\" %\n",
    "                (step * 1.0 / epoch_size, np.exp(losses / iters),\n",
    "                iters * batch_size / (time.time() - start_time)))\n",
    "    \n",
    "    return np.exp(losses / iters)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_max_epoch):\n",
    "\n",
    "    print(\"Epoch: %d\" % (i + 1))\n",
    "\n",
    "    train_perplexity = run_epoch(model, train_data, batch_size, num_steps, verbose=True)\n",
    "    print(\"Train Perplexity: %.3f\" % train_perplexity)\n",
    "\n",
    "    valid_perplexity = run_epoch(model, valid_data, batch_size, num_steps)\n",
    "    print(\"Valid Perplexity: %.3f\" % valid_perplexity + \"\\n\")\n",
    "\n",
    "test_perplexity = run_epoch(model, test_data, batch_size, num_steps) #batch_size_test & num_steps_test -> \n",
    "                                                                     #error embedding shape\n",
    "print(\"Test Perplexity: %.3f\" % test_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика <b>Perplexity</b> (растерянность) отражает распределение вероятностей предсказания объекта p и считается по следующей формуле:\n",
    "\n",
    "<img src=\"images/rnn-lang-modeling/perplexity.png\" width=\"231px\">\n",
    "\n",
    "В обработке естественного языка растерянность позволяет оценить языковые модели, подсчитывая обратную вероятность появления каждого последующего слова в сгенерированном тексте на основе распределения вероятностей обучающей выборки и выражается в двойке в положительной степени (чем ближе этот показатель к двум, тем точнее работает модель)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. Генерация текста</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование индексов в слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {}\n",
    "for c, i in vocabulary.items():\n",
    "    id_to_word[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входная последовательность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"raising money for\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = seed_text\n",
    "sentence = [vocabulary[word] for word in seed_text.split(\" \")]\n",
    "\n",
    "for i in range(text_length):\n",
    "    preds = model.predict(pad_sequences([sentence] * batch_size,\n",
    "                                       maxlen=num_steps))[0]\n",
    "    \n",
    "    preds = np.log(preds) / 1.5\n",
    "    preds = np.exp(preds) / np.sum(np.exp(preds))\n",
    "    next_index = np.argmax(np.random.multinomial(1, preds, 1))\n",
    "    sentence = sentence[1:] + next_index\n",
    "    \n",
    "    next_word = id_to_word[next_index]\n",
    "    feed = feed + \" \" + next_word\n",
    "\n",
    "print(feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">5. Источники</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/tree/master/tutorials/rnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
